{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 19.5 연습문제"
      ],
      "metadata": {
        "id": "HSDPBscEgIlL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aUSVV1-Eekgc",
        "outputId": "bae4440d-dcc1-4c7e-f812-833cd58dd408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  98100      0 --:--:-- --:--:-- --:--:-- 98100\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "61 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tensorflow-model-server is already the newest version (2.7.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 61 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "    !apt update && apt-get install -y tensorflow-model-server\n",
        "    %pip install -q -U tensorflow-serving-api\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deploy\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. (원하는 어떤 모델이든) 모델을 훈련하고 TF 서빙이나 구글 클라우드 AI 플랫폼에 배포해보세요. REST API나 gRPC API를 사용해 쿼리하는 클라이언트 코드를 작성해보세요. 모델을 업데이트하고 새로운 버전을 배포해보세요. 클라이언트가 새로운 버전으로 쿼리할 것입니다. 첫 번째 버전으로 롤백해보세요."
      ],
      "metadata": {
        "id": "mvH7BM_4gfwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## => mnist 모델"
      ],
      "metadata": {
        "id": "2bjaLMpjgkDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gc5PkGFlekgt"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j_az5Mpnekgv",
        "outputId": "f6e326e2-fbb3-4432-c32f-9327d7a7c1ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7012 - accuracy: 0.8241 - val_loss: 0.3715 - val_accuracy: 0.9024\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3536 - accuracy: 0.9020 - val_loss: 0.2990 - val_accuracy: 0.9144\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3036 - accuracy: 0.9145 - val_loss: 0.2651 - val_accuracy: 0.9272\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2736 - accuracy: 0.9231 - val_loss: 0.2436 - val_accuracy: 0.9334\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2509 - accuracy: 0.9296 - val_loss: 0.2257 - val_accuracy: 0.9364\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2322 - accuracy: 0.9350 - val_loss: 0.2121 - val_accuracy: 0.9396\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2161 - accuracy: 0.9401 - val_loss: 0.1970 - val_accuracy: 0.9454\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2021 - accuracy: 0.9432 - val_loss: 0.1880 - val_accuracy: 0.9476\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1898 - accuracy: 0.9471 - val_loss: 0.1778 - val_accuracy: 0.9524\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1793 - accuracy: 0.9493 - val_loss: 0.1685 - val_accuracy: 0.9540\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8160223e90>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QpzmGmJJekgz",
        "outputId": "807cd154-614a-41ce-9006-638f54d50e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.round(model.predict(X_new), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iJdk-exaekg1",
        "outputId": "3a57d9da-65ff-493b-f6de-30821a10b47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my_mnist_model/0001'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model_version = \"0001\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vJ8ONZhxekg3"
      },
      "outputs": [],
      "source": [
        "!rm -rf {model_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SavedModel로 내보내기"
      ],
      "metadata": {
        "id": "g0IUtKsgtNqZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7FpGgCfCekg5",
        "outputId": "d1c82993-d0a3-4270-a361-3cf0afd59c85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_mnist_model/0001/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C3YkzSiCekg6",
        "outputId": "aaec0362-9fb0-4ad9-cfd1-0b8e49228257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_mnist_model/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        assets/\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n"
          ]
        }
      ],
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SavedModel 검사 : saved_model_cli"
      ],
      "metadata": {
        "id": "f7pjIieUtUpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bpODEbVkekg8",
        "outputId": "e4a995f6-5906-41a6-9ba4-d7985aa60201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel contains the following tag-sets:\n",
            "'serve'\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HqxkdVDmekg9",
        "outputId": "bff0d65c-1a6b-419d-9876-719e3c75fe6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "opgG0ubdekg_",
        "outputId": "6a4c6b29-0807-478a-f473-c3c30dd41d62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['flatten_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_flatten_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_1'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "64pz7pYuekhB",
        "outputId": "ace94ae6-2dd0-4649-91b8-58650b65ede5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['flatten_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_flatten_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path} --all"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# saved_model_cli 명령을 사용해 예측"
      ],
      "metadata": {
        "id": "cZVtEd9Utdvr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KM8QZuvlekhD"
      },
      "outputs": [],
      "source": [
        "np.save(\"my_mnist_tests.npy\", X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NtjCau5zekhE",
        "outputId": "bdb7ec6b-4f89-4807-90bc-fb1e725b7817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'flatten_input'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "input_name = model.input_names[0]\n",
        "input_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u8PNzRovekhF",
        "outputId": "643212ec-ec09-4cd5-8857-a2a3ac30338a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-09 16:39:16.730798: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/tools/saved_model_cli.py:453: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from my_mnist_model/0001/variables/variables\n",
            "Result for output key dense_1:\n",
            "[[1.1425162e-04 1.5136652e-07 9.8184170e-04 2.7773476e-03 3.7588777e-06\n",
            "  7.6266384e-05 3.9139518e-08 9.9556208e-01 5.3445750e-05 4.3088064e-04]\n",
            " [8.1948563e-04 3.5498284e-05 9.8824197e-01 7.0574451e-03 1.2937063e-07\n",
            "  2.3402784e-04 2.5743369e-03 9.6684483e-10 1.0369361e-03 8.8335582e-08]\n",
            " [4.4415643e-05 9.7032869e-01 9.0444442e-03 2.2599059e-03 4.8672187e-04\n",
            "  2.8736168e-03 2.2682848e-03 8.3548538e-03 4.0413244e-03 2.9782380e-04]]\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli run --dir {model_path} --tag_set serve \\\n",
        "                     --signature_def serving_default    \\\n",
        "                     --inputs {input_name}=my_mnist_tests.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UqXd_5mWekhG",
        "outputId": "1e428930-1ea6-43ee-f79e-af2ece194050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "np.round([[1.1347984e-04, 1.5187356e-07, 9.7032893e-04, 2.7640699e-03, 3.7826971e-06,\n",
        "           7.6876910e-05, 3.9140293e-08, 9.9559116e-01, 5.3502394e-05, 4.2665208e-04],\n",
        "          [8.2443521e-04, 3.5493889e-05, 9.8826385e-01, 7.0466995e-03, 1.2957400e-07,\n",
        "           2.3389691e-04, 2.5639210e-03, 9.5886099e-10, 1.0314899e-03, 8.7952529e-08],\n",
        "          [4.4693781e-05, 9.7028232e-01, 9.0526715e-03, 2.2641101e-03, 4.8766597e-04,\n",
        "           2.8800720e-03, 2.2714981e-03, 8.3753867e-03, 4.0439744e-03, 2.9759688e-04]], 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUT9Fm_WekhH"
      },
      "source": [
        "## 텐서플로 서빙 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KWDqMgGXekhJ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MODEL_DIR\"] = os.path.split(os.path.abspath(model_path))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "28HkngqDekhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceff43ad-f3d1-474d-9856-214a8261d5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ]
        }
      ],
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "     --rest_api_port=8501 \\\n",
        "     --model_name=my_mnist_model \\\n",
        "     --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2SXkRoFYekhL",
        "outputId": "56e89a24-fed5-4545-c693-1cd05dad1cd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 230] NET_LOG: Couldn't bind to port 8501\n",
            "[evhttp_server.cc : 63] NET_LOG: Server has not been terminated. Force termination now.\n",
            "[evhttp_server.cc : 265] NET_LOG: Server is not running ...\n",
            "2022-01-09 16:39:32.328974: E tensorflow_serving/model_servers/server.cc:432] Failed to start HTTP Server at localhost:8501\n"
          ]
        }
      ],
      "source": [
        "!tail server.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ri33mFwsekhL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_data_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YRBvD30JekhM",
        "outputId": "b3e98b70-7075-41f7-8f69-07c176bdc671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.32941177487373...'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "repr(input_data_json)[:1500] + \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Meqvc-isekhN"
      },
      "source": [
        "# REST API로 TF 서빙에 쿼리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nYfbGPgFekhN"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status() # 에러 발생 -> 예외 발생\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Wos8Jvb6ekhO",
        "outputId": "9d6a16c4-5b00-4e2a-aac8-2ed2d692f36f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "74r0JxmGekhO",
        "outputId": "0816129c-239d-4636-a04a-af13c1d85b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfu85cvXekhP"
      },
      "source": [
        "# gRPC API로 TF 서빙에 쿼리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pcgL7h0yekhQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0]\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-cweSlIjekhR"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jUeRgVExekhS",
        "outputId": "8d0ed141-cd5b-401b-e5e4-e7b0fb5963f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "outputs {\n",
              "  key: \"dense_1\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "      dim {\n",
              "        size: 10\n",
              "      }\n",
              "    }\n",
              "    float_val: 0.00011425172124290839\n",
              "    float_val: 1.5136652109504212e-07\n",
              "    float_val: 0.0009818424005061388\n",
              "    float_val: 0.002777349902316928\n",
              "    float_val: 3.758880893656169e-06\n",
              "    float_val: 7.6266449468676e-05\n",
              "    float_val: 3.9139518293040965e-08\n",
              "    float_val: 0.995561957359314\n",
              "    float_val: 5.344580131350085e-05\n",
              "    float_val: 0.00043088122038170695\n",
              "    float_val: 0.000819486565887928\n",
              "    float_val: 3.5498320357874036e-05\n",
              "    float_val: 0.9882420897483826\n",
              "    float_val: 0.007057449780404568\n",
              "    float_val: 1.2937064752804872e-07\n",
              "    float_val: 0.00023402832448482513\n",
              "    float_val: 0.0025743397418409586\n",
              "    float_val: 9.668431610876382e-10\n",
              "    float_val: 0.0010369382798671722\n",
              "    float_val: 8.833576714550873e-08\n",
              "    float_val: 4.441547571332194e-05\n",
              "    float_val: 0.970328688621521\n",
              "    float_val: 0.009044423699378967\n",
              "    float_val: 0.0022599007934331894\n",
              "    float_val: 0.00048672096454538405\n",
              "    float_val: 0.002873610006645322\n",
              "    float_val: 0.002268279204145074\n",
              "    float_val: 0.008354829624295235\n",
              "    float_val: 0.004041312728077173\n",
              "    float_val: 0.0002978229313157499\n",
              "  }\n",
              "}\n",
              "model_spec {\n",
              "  name: \"my_mnist_model\"\n",
              "  version {\n",
              "    value: 1\n",
              "  }\n",
              "  signature_name: \"serving_default\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "id": "Svm72wXRekhT",
        "outputId": "817a7ae4-552a-4f8e-fc22-53a64198137a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5ChHS92nekhU",
        "outputId": "aa577884-4a51-44a1-a45c-444cd928b985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCB-6lpSekhV"
      },
      "source": [
        "## 새로운 버전의 모델 배포하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "scrolled": true,
        "id": "ZN5QBt09ekhV",
        "outputId": "bb2b128c-7312-43b1-c094-674ae7e2dbb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.7039 - accuracy: 0.8056 - val_loss: 0.3418 - val_accuracy: 0.9042\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3204 - accuracy: 0.9082 - val_loss: 0.2674 - val_accuracy: 0.9244\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2650 - accuracy: 0.9235 - val_loss: 0.2226 - val_accuracy: 0.9368\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2318 - accuracy: 0.9329 - val_loss: 0.2031 - val_accuracy: 0.9428\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2088 - accuracy: 0.9398 - val_loss: 0.1832 - val_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1908 - accuracy: 0.9447 - val_loss: 0.1741 - val_accuracy: 0.9498\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1756 - accuracy: 0.9491 - val_loss: 0.1605 - val_accuracy: 0.9542\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1631 - accuracy: 0.9524 - val_loss: 0.1546 - val_accuracy: 0.9558\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1517 - accuracy: 0.9568 - val_loss: 0.1461 - val_accuracy: 0.9570\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1429 - accuracy: 0.9584 - val_loss: 0.1360 - val_accuracy: 0.9620\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nPFrT8ThekhW",
        "outputId": "6b358b3e-635b-491b-baa0-4e26b69636bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my_mnist_model/0002'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model_version = \"0002\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dAdXH8HyekhW",
        "outputId": "de3bc065-fb8b-46fa-88db-5b808c3e787b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "m2PFGOP6ekhX",
        "outputId": "63ecad85-f93c-4d5f-d7d7-99169ef65c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_mnist_model/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        assets/\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "    0002/\n",
            "        saved_model.pb\n",
            "        assets/\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n"
          ]
        }
      ],
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PY3RzbqmekhY"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "            \n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xsbXPzk2ekhZ",
        "outputId": "5765c34d-d954-4303-8d83-20a31042fce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WCVot6_qekhZ",
        "outputId": "0cbdd540-3750-4a4e-bd4a-8624b91a33ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 첫 번째 버전으로 롤백"
      ],
      "metadata": {
        "id": "ZIMEjKtouDL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Cu4P4AuE2U",
        "outputId": "f4bc9fa5-582e-4fda-893d-3f22a1d2315c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_mnist_model/\n",
            "    .ipynb_checkpoints/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        assets/\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------"
      ],
      "metadata": {
        "id": "92mEJ7iFuaeN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDR4wyy5ekhh"
      },
      "source": [
        "# 10. 하나의 머신에 여러 개의 GPU에서 MirroredStrategy 전략으로 모델을 훈련해보세요(코랩 GPU 런타임으로 가상 GPU 두 개를 만들 수 있습니다). CentralStorageStrategy 전략으로 모델을 재훈련하고 훈련 시간을 비교해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "86Odcn4Qekhi"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fZseU9B2ekhi"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                            padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"), \n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(units=64, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(units=10, activation='softmax'),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "z74jjmciekhj",
        "outputId": "d45b537e-7c4f-48d4-b143-3a803f522a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "550/550 [==============================] - 13s 21ms/step - loss: 1.2561 - accuracy: 0.6002 - val_loss: 0.3396 - val_accuracy: 0.9016\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.4468 - accuracy: 0.8643 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.3085 - accuracy: 0.9089 - val_loss: 0.1341 - val_accuracy: 0.9616\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 11s 20ms/step - loss: 0.2410 - accuracy: 0.9296 - val_loss: 0.1050 - val_accuracy: 0.9718\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.2025 - accuracy: 0.9426 - val_loss: 0.0866 - val_accuracy: 0.9752\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1810 - accuracy: 0.9464 - val_loss: 0.0796 - val_accuracy: 0.9772\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 12s 21ms/step - loss: 0.1601 - accuracy: 0.9528 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1490 - accuracy: 0.9569 - val_loss: 0.0705 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 11s 20ms/step - loss: 0.1350 - accuracy: 0.9607 - val_loss: 0.0643 - val_accuracy: 0.9816\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 11s 20ms/step - loss: 0.1315 - accuracy: 0.9619 - val_loss: 0.0604 - val_accuracy: 0.9826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f80eca52a90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "batch_size = 100\n",
        "model = create_model()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MirroredStrategy() 전략 사용"
      ],
      "metadata": {
        "id": "T9fFxAH4kgJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dCjbtJteekhj",
        "outputId": "52d1db5e-9560-4ba0-8b39-9c68a5c5f7e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "550/550 [==============================] - 16s 24ms/step - loss: 1.2569 - accuracy: 0.5987 - val_loss: 0.3433 - val_accuracy: 0.8998\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 12s 21ms/step - loss: 0.4473 - accuracy: 0.8647 - val_loss: 0.1953 - val_accuracy: 0.9468\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 12s 21ms/step - loss: 0.3084 - accuracy: 0.9093 - val_loss: 0.1343 - val_accuracy: 0.9626\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 12s 22ms/step - loss: 0.2415 - accuracy: 0.9291 - val_loss: 0.1062 - val_accuracy: 0.9710\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 12s 22ms/step - loss: 0.2026 - accuracy: 0.9425 - val_loss: 0.0872 - val_accuracy: 0.9756\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 12s 22ms/step - loss: 0.1803 - accuracy: 0.9471 - val_loss: 0.0794 - val_accuracy: 0.9768\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 12s 22ms/step - loss: 0.1594 - accuracy: 0.9529 - val_loss: 0.0751 - val_accuracy: 0.9778\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 12s 22ms/step - loss: 0.1479 - accuracy: 0.9569 - val_loss: 0.0703 - val_accuracy: 0.9800\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 12s 22ms/step - loss: 0.1341 - accuracy: 0.9610 - val_loss: 0.0637 - val_accuracy: 0.9822\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 12s 21ms/step - loss: 0.1305 - accuracy: 0.9627 - val_loss: 0.0602 - val_accuracy: 0.9824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "batch_size = 100 # 복제 모델 개수로 나누어 떨어져야 합니다.\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)\n",
        "\n",
        "model.predict(X_new).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CentralStorageStrategy 전략 사용"
      ],
      "metadata": {
        "id": "FxbyzraDkXYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zN3cbLbdekhm",
        "outputId": "51cb9d7f-0f61-4e22-cd96-74c96344e34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:GPU:0'\n",
            "Epoch 1/10\n",
            "550/550 [==============================] - 15s 23ms/step - loss: 1.2919 - accuracy: 0.5787 - val_loss: 0.3504 - val_accuracy: 0.9078\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.4810 - accuracy: 0.8548 - val_loss: 0.1909 - val_accuracy: 0.9478\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.3227 - accuracy: 0.9054 - val_loss: 0.1314 - val_accuracy: 0.9624\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.2513 - accuracy: 0.9263 - val_loss: 0.1127 - val_accuracy: 0.9686\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.2099 - accuracy: 0.9395 - val_loss: 0.0896 - val_accuracy: 0.9738\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1851 - accuracy: 0.9458 - val_loss: 0.0834 - val_accuracy: 0.9770\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1642 - accuracy: 0.9518 - val_loss: 0.0732 - val_accuracy: 0.9792\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1528 - accuracy: 0.9556 - val_loss: 0.0710 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1408 - accuracy: 0.9588 - val_loss: 0.0662 - val_accuracy: 0.9818\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 11s 21ms/step - loss: 0.1314 - accuracy: 0.9621 - val_loss: 0.0611 - val_accuracy: 0.9834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "distribution = tf.distribute.experimental.CentralStorageStrategy()\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "batch_size = 100\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)\n",
        "\n",
        "model.predict(X_new).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -> 음... 빠름을 못 느끼겠어요..!!"
      ],
      "metadata": {
        "id": "vSKHBBxLugv6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0pJh204ekh6"
      },
      "source": [
        "# 11. 구글 클라우드 AI 플랫폼에서 블랙 박스 하이퍼파라미터 튜닝으로 작은 모델을 훈련해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 블랙박스 모델 : 동작 원리가 밝혀지지 않은 시스템 (<-> 화이트 박스 모델 : 해석 가능 모델)\n",
        "#### - 입, 출력만 나올 뿐 그 내부 작업은 명확 X\n",
        "#### - 예측된 결과에 대한 이유를 찾을 수 없음 (딥러닝에서의 히든레이어를 분석하는 것이 너무 어렵기 때문)\n",
        "\n",
        "[출처](https://broccoli45.tistory.com/31)"
      ],
      "metadata": {
        "id": "pdXpIIAHmlj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [설명가능한 인공지능(Explainable AI; XAI) 연구 동향과 시사점 학습이 완료된 딥러닝 모델에 대한 설명을 중심으로](https://spri.kr/posts/view/23296?code=industry_trend)\n",
        "딥러닝의 대두 이후 구체적으로 인공지능의 판단이 어떤 매커니즘으로 결론이 도출되었는지 알 수 없어, 생명과 존엄이 관련된 곳에는 도입이 지체됐다. 이를 극복하기 위해 설명가능 인공지능(Explainable AI)의 필요성이 요구됐으나 여전히 기대에 미치지 못하고 블랙박스로 치부되는 실정이다. 본 고는 현실과 이상의 간극을 좁히고자, 실제 설명가능 인공지능 분야의 주요 기법들을 소개한다. 이를 바탕으로 향후 연구지원 정책 방향 등에 대한 시사점을 고민해본다."
      ],
      "metadata": {
        "id": "YEOPeQ1Looh2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPFF8VKekh6"
      },
      "source": [
        "Please follow the instructions on pages 716-717 of the book. You can also read [this documentation page](https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview) and go through the example in this nice [blog post](https://towardsdatascience.com/how-to-do-bayesian-hyper-parameter-tuning-on-a-blackbox-model-882009552c6d) by Lak Lakshmanan."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 구글 클라우드 AI 플랫폼은 베이지안 방식을 사용하는 초매개변수 조정 서비스를 제공함\n",
        "- 베이지안 접근 방식을 사용하여 거의 모든 블랙박스 모델을 조정할 수 있음\n",
        "- 그에 대한 예시가 [blog.post](https://towardsdatascience.com/how-to-do-bayesian-hyper-parameter-tuning-on-a-blackbox-model-882009552c6d)임\n",
        "\n",
        "    1. 최적화할 블랙박스 기능 호출\n",
        "    2. 최적화 가능한 각 매개변수를 명령줄 매개변수로 만듦\n",
        "    3. hypertune 패키지를 사용하여 최적화하려는 metric을 작성\n",
        "    4. hyperparam.yaml 파일 작성(최적화하려는 metric 이름, 제약 조건)\n",
        "    5. 하이퍼파라미터 튜닝 작업을 REST API or Python or 명령줄에서 gcloud를 사용하여 ML Engie에 제출\n",
        "    6. GCP 콘솔에서 튜닝 결과보기"
      ],
      "metadata": {
        "id": "wy_xVUYgpW2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 번외\n",
        "Optuna : 머신 러닝 프레임 워크 및 블랙 박스 최적화 솔버에 적용 할 수있는 하이퍼 파라미터 최적화 프레임 워크\n",
        "- 파라미터들과의 관계, 상관관계, 중요도 등도 확인 가능\n"
      ],
      "metadata": {
        "id": "gcXEji9brNM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [하이퍼파라미터 튜닝을 쉽고 빠르게 하는 방법](https://www.dacon.io/codeshare/2704?page=1&dtype=recent&s_id=0)\n",
        "\n",
        "### [Optuna를 이용한 hyper parameter optimization - 파이토치를 이용해서 mnist 분류할 때](https://jeonghwarr.github.io/tips/optuna%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_hyper_parameter_optimization/)"
      ],
      "metadata": {
        "id": "u16HBJN7rQkW"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "19장 대규모 텐서플로 모델 훈련과 배포",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}