{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "16.1 Char-RNN을 사용해 셰익스피어 문체 생성하기.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH_0wB_YRVNa"
      },
      "source": [
        "# 16.1 Char-RNN을 사용해 셰익스피어 문체 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1q2sGsRRetJ"
      },
      "source": [
        "## 16.1.1 훈련 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYyTu-htQxhX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDrf2dlvR2dI",
        "outputId": "b2ade19b-1cd7-426f-f4b7-66165d339108"
      },
      "source": [
        "# 셰익스피어 작품 모두 다운로드\n",
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4PRDLN0SF4W",
        "outputId": "61eca046-591e-4cd4-a23a-e9f8c14b9801"
      },
      "source": [
        "print(shakespeare_text[:148])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTGZcQxyScwA"
      },
      "source": [
        "# 모든 글자를 정수로 인코딩\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True) # char_level : 글자 수준 인코딩\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn3Mbg8NSfBQ",
        "outputId": "f2b31b9d-b423-4bde-9713-48cdf6ff8fcc"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"First\"]) # 숫자로"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms77Q_iXSo3-",
        "outputId": "8d0956a7-77d0-4c76-a092-faf49106b5d0"
      },
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]]) # 문자로"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsRINu8rSuMq"
      },
      "source": [
        "max_id = len(tokenizer.word_index) # 고유 글자 개수\n",
        "dataset_size = tokenizer.document_count # 전체 글자 개수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OezFfWgwS1mR"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1 # 전체 텍스트를 인코딩하여 각 글자를 ID로 나타내기, 1에서 39까지 대신 0에서 38까지 ID를 얻기 위해 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf4NjBJlS61O",
        "outputId": "f8a56f84-2490-425f-8d46-0ecac03e6e53"
      },
      "source": [
        "[encoded]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([19,  5,  8, ..., 20, 26, 10])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqWCMzTBTIiA"
      },
      "source": [
        "## 16.1.2 순차 데이터셋을 나누는 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlrIn5hRTa_b"
      },
      "source": [
        "#### 시계열을 훈련 셋, 검증 셋, 테스트 셋으로 나누는 것은 간단한 작업 X\n",
        "#### 주어진 문제에 따라 달라짐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlWDHl3LTFMP"
      },
      "source": [
        "# 여기에서는 텍스트의 처음 90%를 훈련 세트로 사용\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBpKjPX4Toi0"
      },
      "source": [
        "## 16.1.3 순차 데이터를 윈도 여러 개로 자르기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfymv8vJTVpr"
      },
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = 1글자 앞의 input\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True) # shift=1 : 가장 큰 훈련 세트를 만들 수 있음, drop_remainer=True : 모든 윈도가 동일한 글자수를 포함하도록"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeRaACTT01C"
      },
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length)) # 훈련에 중첩 데이터셋을 바로 사용할 수 없음 -> 플랫 데이테 셋으로 만들기 ex) {{1, 2}, {3, 4, 5, 6}} = {1, 2, 3, 4, 5, 6}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U30WWZAwUfzQ"
      },
      "source": [
        "# 윈도를 배치로 만들기 및 입력과 타깃을 분리하기\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR17UnQfVJFn"
      },
      "source": [
        "# 범주형 입력 특성 -> 원핫 벡터나 임베딩으로 인코딩 해야 함\n",
        "# 여기서는 고유한 그자 수가 적기 때문에 원핫 벡터 이용\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aznNnJAQVVRl"
      },
      "source": [
        "# 프리페칭 추가\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIcuVV47Vc9p"
      },
      "source": [
        "## 16.1.4 Char-RNN 모델 만들고 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCyAAqMAVnge"
      },
      "source": [
        "#### 이전 글자 100개를 기반으로 다음 글자를 예측\n",
        "- 유닛 128개를 가진 GRU 층 2개\n",
        "- 입력과 은닉 상태에 20% 드롭아웃 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3cIYi5jVZcZ",
        "outputId": "35b7ed29-d185-49ae-e4b9-3f01857b1b37"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     #dropout=0.2, recurrent_dropout=0.2), # 순환 드롭아웃 : 너무 느려요ㅠㅠㅠ\n",
        "                     dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "31368/31368 [==============================] - 1627s 52ms/step - loss: 1.6210\n",
            "Epoch 2/10\n",
            "31368/31368 [==============================] - 1620s 52ms/step - loss: 1.5351\n",
            "Epoch 3/10\n",
            "31368/31368 [==============================] - 1621s 52ms/step - loss: 1.5124\n",
            "Epoch 4/10\n",
            "31368/31368 [==============================] - 1623s 52ms/step - loss: 1.5002\n",
            "Epoch 5/10\n",
            "31368/31368 [==============================] - 1623s 52ms/step - loss: 1.4923\n",
            "Epoch 6/10\n",
            "31368/31368 [==============================] - 1636s 52ms/step - loss: 1.4871\n",
            "Epoch 7/10\n",
            "31368/31368 [==============================] - 1648s 52ms/step - loss: 1.4828\n",
            "Epoch 8/10\n",
            "31368/31368 [==============================] - 1644s 52ms/step - loss: 1.4798\n",
            "Epoch 9/10\n",
            "31368/31368 [==============================] - 1642s 52ms/step - loss: 1.4767\n",
            "Epoch 10/10\n",
            "31368/31368 [==============================] - 1647s 52ms/step - loss: 1.4750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AWutsLXWseM"
      },
      "source": [
        "## 16.1.5 Char-RNN 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S4FnCGaV_Ae"
      },
      "source": [
        "# 새로운 텍스트 넣으려면?! 전처리 함수\n",
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqjmAWBnW1z2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1da22db7-87b9-465f-9407-c9e135167449"
      },
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "Y_pred = np.argmax(model(X_new), axis=-1)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 첫 번째 문장, 마지막 글자"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'u'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7n6jDglXEJ8"
      },
      "source": [
        "## 16.1.6 가짜 셰익스피어 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF3IZKu2XIDP"
      },
      "source": [
        "#### 새로운 텍스트 생성?\n",
        "1. 초기 텍스트 입력\n",
        "2. 모델이 가장 가능성 있는 다음 글자 예측\n",
        "3. 예측된 글자를 가지고 늘어난 텍스트를 모델에 전달하여 다음 글자 예측\n",
        "But, 같은 단어가 반복되는 경우가 많음  \n",
        "=> tf.random.categorical() 함수를 사용해 모델이 추정한 확률을 기반으로 다음 글자를 무작위로 선택 O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-0G5jkfXDYH"
      },
      "source": [
        "# 다음 글자를 선택하고 입력 텍스트에 추가\n",
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature # 생성된 텍스트의 다양성을 더 많이 제어하려면? 온도라고 불리는 숫자를 로짓으로 나눔 (0에 가까울수록 높은 확률을 가진 글자를 선택)\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHIo6holXmDN"
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L75-PihYAhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3336e31a-a4d4-4401-b79a-569ea656329f"
      },
      "source": [
        "print(complete_text(\"t\", temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the man of all the rest was the words of signior ba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0WkDuAFYGB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef99250a-4d7f-4681-a61b-9426b682bc20"
      },
      "source": [
        "print(complete_text(\"t\", temperature=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t od sirrah, so please thee wiolds:\n",
            "i wrong'd to be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmsMbDB3YIPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9298b73b-bc98-49fa-c770-c5dd6de533df"
      },
      "source": [
        "print(complete_text(\"t\", temperature=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tem face? tigli, higlle's gotd hibhrel.-\n",
            "ane himn a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjKeBjCxYNxQ"
      },
      "source": [
        "#### 조금 더 좋은 성능?\n",
        "- GRU 층과 층의 뉴런 수를 늘리고 더 오래 훈련하거나 규제(recurrent_dropout=0.3) 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUC-divOYbEq"
      },
      "source": [
        "- 현재 모델은 100보다 긴 패턴 학습 X\n",
        "- 윈도를 크게 할 수 있지만 학습 어려워짐\n",
        "- LSTM과 GRU 셀이라도 매우 긴 시퀀스는 다룰 수 X\n",
        "- 아니면 상태가 있는 RNN 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WqI4jkBYo4d"
      },
      "source": [
        "## 16.1.7 상태가 있는 RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLToMPO7Yy4O"
      },
      "source": [
        "- RNN이 한 훈련 배치를 처리한 후에 마지막 상태를 다음 훈련 배치의 초기 상태로 사용?   -> 역전파는 짧은 시퀀스에서 일어나지만 모델이 장기간 패턴을 학습할 수 있음  \n",
        "=> 상태가 있는 RNN\n",
        "\n",
        "- 상태가 있는 RNN 만드는 방법\n",
        "1. 순차적이고 겹치지 않는 입력 시퀀스 만들기  \n",
        "Why? 배치에 있는 각 입력 시퀀스가 이전 배치의 시퀀스가 끝난 지점에서 시작해야 함\n",
        "2. Dataset을 만들 때 window() 메서드에서 shift=n_steps 사용\n",
        "3. shuffle() 메서드 호출 X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQoiAgtXYXrL"
      },
      "source": [
        "# 하나의 윈도를 갖는 배치를 만들어야 함\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "dataset = dataset.batch(1)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM0eAFXqi_pP"
      },
      "source": [
        "batch_size = 32\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "    datasets.append(dataset)\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNgRePH6ZynI"
      },
      "source": [
        "# 상태가 있는 RNN 모델 생성시 포인트!\n",
        "# stateful=True 지정해야 함\n",
        "# 배치 크기 알아야 함 => 첫 번째 층에 batch_input_shape 매개변수를 지정해야 함\n",
        "# 입력은 어떤 길이도 가질 수 있으므로 두 번째 차원은 지정하지 않아도 됨\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2,\n",
        "                     dropout=0.2,\n",
        "                     batch_input_shape=[batch_size, None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf3SDuPNaK61"
      },
      "source": [
        "# 에포크 끝마다 텍스트를 다시 시작하기 전에 상태를 재설정 해야 함\n",
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpgxCHmBaQES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd40d9d8-1b26-44b9-c812-04a362d93b1c"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=50,\n",
        "                    callbacks=[ResetStatesCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "      6/Unknown - 3s 54ms/step - loss: 3.6243WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.0264s). Check your callbacks.\n",
            "313/313 [==============================] - 19s 52ms/step - loss: 2.6270\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 2.2420\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 2.1096\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 2.0326\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.9810\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.9434\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.9154\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8943\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8766\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.8632\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8493\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8370\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8289\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8208\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8126\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.8045\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7985\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7909\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7861\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7827\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7782\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7737\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7701\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7677\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7620\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7576\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7558\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7553\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7510\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7474\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7451\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7418\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7416\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7395\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7362\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7351\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7331\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7289\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7270\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7257\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7250\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7230\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7216\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7215\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7196\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7165\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7167\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7157\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7127\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jNsqjWSaXEU"
      },
      "source": [
        "#### 이 모델은 훈련할 때 사용한 것과 동일한 크기의 배치로만 예측이 가능! 이러한 제약을 없애기 위해서는 동일한 구조의 상태가 없는 모델을 만들고 상태가 있는 모델의 가중치를 복사하면 됨"
      ]
    }
  ]
}