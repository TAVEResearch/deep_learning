{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13.1 데이터 API",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puPvyTHCSyBT"
      },
      "source": [
        "*13.1 데이터 API*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGJNBD3iUGAR",
        "outputId": "9c690850-7bc4-4172-f724-d6636cdcd315"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "X = tf.range(10) #0부터 9까지의 10개의 아이템을 가짐\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5sYqsncS8Zy"
      },
      "source": [
        "tf.data.Dataset.from_tensor_slices() 사용해 전체 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMO5AHAUQoD",
        "outputId": "ab851f29-d993-4447-a261-1046af912972"
      },
      "source": [
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLzAUp76WwA1"
      },
      "source": [
        "데이터셋이 준비되었습니다!\n",
        "\n",
        "*13.1.1 연쇄변환*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4XyGBAhccFX",
        "outputId": "5b5aad76-8f02-4443-b3c7-3a5e49a23e50"
      },
      "source": [
        "dataset = dataset.repeat(3). batch(7)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "3DaFQ8Rcd5Lg",
        "outputId": "6de8a1c2-b943-4a4f-e090-e2c4c6721bfb"
      },
      "source": [
        "dataset = dataset.repeat(3).batch(7, drop_remainer=True)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-3bf116e50755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: batch() got an unexpected keyword argument 'drop_remainer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7tEaOHMflj-"
      },
      "source": [
        "책에서 batch()메서드를 drop_remainder = True로 호출하면 모든 배치가 일정한 크기로 맞춰진다고 했는데 실패했어요 🥲\n",
        "\n",
        "데이터셋 메서드는 데이터셋을 바꾸지 않고 새로운 데이터셋을 만드므로 꼭 새로운 데이터셋을 반환받아야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gpoarxue0Sx"
      },
      "source": [
        "dataset = dataset.map(lambda x:x*2) #아이템:[0,2,4,6,8,10,12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsPe1Xw1gQSQ"
      },
      "source": [
        "\n",
        "\n",
        "* 모든 아이템에 2를 곱해 새로운 데이터셋을 만듭니다.\n",
        "*   항목 추가\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3J6LoQjhKlj"
      },
      "source": [
        "dataset = dataset.apply(tf.data.experimental.unbatch())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4rihFrHjJ84"
      },
      "source": [
        "apply() 메서드는 unbatch() 함수를 적용하는데 현재 실험적입니다.\n",
        "\n",
        "새로 만들어진 데이터셋의 각 아이템은 7개의 정수로 이루어진 배치가 아니라 하나의 정수텐서가 됩니다.\n",
        "\n",
        "하지만 텐서플로에서는 더이상 쓰이지 않는다고 되어 있었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN7Mrk89iqSM"
      },
      "source": [
        "dataset = dataset.filter(lambda x: x<10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o3QUtmHjsXk"
      },
      "source": [
        "for item in dataset.take(3):\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MiGhzR9kn-I"
      },
      "source": [
        "\n",
        "*   take()메서드\n",
        "\n",
        "*   데이터셋에 있는 몇 개의 아이템만 필터링해 볼 수도 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ocph_nAk-Ye"
      },
      "source": [
        "*13.1.2 데이터 셔플링*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWlXHYBbtPZd"
      },
      "source": [
        "\n",
        "\n",
        "*   원본 -> 버퍼 -> 반환\n",
        "*   원본 데이터셋의 모든 아이템을 쓸 때까지\n",
        "*   버퍼가 비워질 때까지 (버퍼 충분히 크게)\n",
        "*   메모리 크기 초과 X\n",
        "*   데이터셋 크기 초과 X\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "[링크 텍스트](https://)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT24cGymtOzA"
      },
      "source": [
        "dataset = tf. data. Dataset. range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoTJGPxqvsUH"
      },
      "source": [
        "정수 0에서 9까지 세 번 반복된 데이터셋을 버퍼 크기5, 랜덤시드 42 통해 셔플링한 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM2AruDyj9ub"
      },
      "source": [
        "dataset = tf. data. Dataset. range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42, reshuffle_each_iteration=False).batch(7)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWweLy5Tu3li"
      },
      "source": [
        "반복마다 동일한 순서를 사용해야 한다면 reshuffle_each_interaction=False를 지정해야 하는데 \n",
        "\n",
        "동일한 순서가 나오지 않았어요 🥲"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPbIoRznwYW4"
      },
      "source": [
        "메모리 용량보다 큰 데이터셋은 셔플링만을 충분하지 않아\n",
        "\n",
        "원본 데이터 자체를 섞어야 합니다.\n",
        "\n",
        "ex. 리눅스에서 shuf 명령어 통해 텍스트 섞음\n",
        "\n",
        "에포크마다 한 번 더 섞기!\n",
        "\n",
        "편향 방지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsvzDIXR17u3"
      },
      "source": [
        "*13.1.3 데이터 전처리*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxmKkjtM3tb9"
      },
      "source": [
        "X_mean, X_std = [0,1]\n",
        "n_inputs = 8\n",
        "\n",
        "def preprocess(line):\n",
        "  defs =[0.] * n_inputs + [tf.constant([],dtype=tf.float32)]\n",
        "  fields = tf.io.decode_csv(line,record_defaults=defs)\n",
        "  x= tf.stack(fields[:-1])\n",
        "  y= tf.stack(fields[-1:])\n",
        "  return (x - X_mean) / X_std, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SV0y9Gk55-w"
      },
      "source": [
        "X_mean과 X_std는 1개씩 8개의 실수를 가진 1D 텐서\n",
        "\n",
        "파싱할 라인과 CSV파일의 각 열에 대한 기본 값\n",
        "\n",
        "decode_csv()   스칼라 텐서 리스트 반환\n",
        "\n",
        "tf.stack 함수 (마지막 열 빼고) 스칼라 텐서 -> 하나의 값을 가진 1D 텐서\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRFHVuYG3tgs",
        "outputId": "057b5738-dbb3-476c-9852-935d8a30ae83"
      },
      "source": [
        "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([   4.2083,   44.    ,    5.3232,    0.9171,  846.    ,    2.337 ,\n",
              "          37.47  , -122.2   ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wq5MDjQusBi"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, Y_class_train),(X_train, Y_class_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLyDqlLcKXpa"
      },
      "source": [
        "번외\n",
        "\n",
        "케라스를 이용해 mnist 손글씨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgnjN0-fIeIl"
      },
      "source": [
        "*13.1.4 데이터 적재와 전처리를 합치기*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCqYNWoq3tjf"
      },
      "source": [
        "def csv_reader_dataset(filepaths,repeat=1, n_readers=5,\n",
        "                       n_read_threads=None, shuffle_buffer_size= 10000,\n",
        "                       n_parse_threads=5, batch_size = 32):\n",
        "  dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
        "  dataset = dataset.interleave(\n",
        "      lambda filepath: tf.data.TextLineDataser(filepath).skip(1),\n",
        "      cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "  dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "  dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "  return dataset.batch(batch_size).prefetch(1)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu11oVj1KycQ"
      },
      "source": [
        "CSV 파일에서 캘리포니아 주택 데이터셋 적재, 전처리, 셔플링, 반복, 배치를 적용한 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5aPZQATLT5C"
      },
      "source": [
        "*13.1.5 프리페치*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9GB5b7oLjjX"
      },
      "source": [
        "\n",
        "\n",
        "*   prefetch(1)\n",
        "*   항상 한 배치가 미리 준비되도록\n",
        "*   성능 향상: interleave()와 map() 메서드 호출할 때 num_parallel_calls 매개변수 지정\n",
        "*   CPU와 GPU를 동시에 사용: GPU가 한 배치 처리할 때 CPU가 그 다음 배치 준비\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3jAh-PlMOz2"
      },
      "source": [
        "\n",
        "자주 쓰는 데이터셋 메서드\n",
        "*   concatenate() \n",
        "*   zip()\n",
        "*   window()\n",
        "*   reduce()\n",
        "*   shard()\n",
        "*   flat_map()\n",
        "*   padded_batch()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m567XK1_NLN_"
      },
      "source": [
        "*13.1.6 tf.keras와 데이터셋 이용하기*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaedJ2AjQ-kN"
      },
      "source": [
        "keras에서 반복을 처리하므로 반복을 지정할 필요가 없다.\n",
        "\n",
        "데이터셋(검증 세트, 테스트 세트) -> 케라스 모델 만들기 -> 훈련셋과 검증셋 전달"
      ]
    }
  ]
}